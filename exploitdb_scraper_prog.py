from ExploitReader import parseExploitUrl
import pandas as pd
import os
from time import sleep #zZzZzZz
import pickle
from tqdm import tqdm
import glob

"""
Short script to scrape entries in exploitdb
NOTE: might take hours to run
"""

def save_obj(obj, path ):
    with open(path, 'wb') as f:
        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)
        
def load_obj(path ):
    with open(path, 'rb') as f:
        return pickle.load(f)
    
    


def exploitdb_scraper():
    """
    scraper function to read data
    """
    #use smart path join for windows/mac issues
    exploit_data_location = os.path.join('data', 'exploitdb.csv')
    #read the csv
    exploit_df = pd.read_csv(exploit_data_location, index_col=0)
    
    #instantiate i
    i = 0
    
    #exploit_metadata_arr = []
    for url in exploit_df['url']:
                
        #get the exploit number
        exploit_num = str(url.split('/')[-1])
        path = os.path.join('exploitdb_dicts', exploit_num+'.pkl')
        
        
        #check if job is already done
        if not os.path.isfile(path):
            
            #announce the work
            print("Extracting from... {}".format(url))
        
            #get th url
            exploit_db_dict = parseExploitUrl(url)
            #save the work
            save_obj(obj = exploit_db_dict, path = path)
        
            #delete after completion
            del exploit_db_dict
            #concatenate i
            i += 1
            
            
            #sleep for a minute every 20 seconds
            if i % 20 == 0:
                print(10*'zZz' + ' Nap Time ' + 10*'zZz')
                sleep(60)
            
            
        else:
            print("Skipping {} ... File Already exists".format(url))
            
            
def main():
    
    #run the scraper
    exploitdb_scraper()
    
    
    exploitdb_array = []
    for file in tqdm(glob.glob('exploitdb_dicts/*.pkl')):
        #load object
        obj = load_obj(file)
        #append to array
        exploitdb_array.append(obj)
    
    #make dataframe
    exploitdb_df = pd.DataFrame(exploitdb_array)
    
    exploitdb_df.to_csv(os.path.join('data', 'exploitdb_metadata.csv'))

    
    
    
            
            
        
if __name__ == "__main__":
    main()
        

        

        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        