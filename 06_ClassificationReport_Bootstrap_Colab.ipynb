{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_ClassificationReport_Hist_Colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6COlvzqpMbL-"
      },
      "source": [
        "# Bootstrap: How Reliable are the results?\n",
        "\n",
        "In this section I perform a bootsrap to get an idea of how dispered the scoring metrics are. The steps are:\n",
        "- Load the features and target matrices\n",
        "- Randomly split in train and test\n",
        "- Fit to train data\n",
        "- Predict the test data\n",
        "- Make note of metrics\n",
        "- Rinse and repeat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYSdt-7DctPl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from time import time\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix,plot_roc_curve,plot_precision_recall_curve,plot_confusion_matrix, classification_report\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import xgboost as xgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FMzWo82dyKn"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgLRQv5gcyNx"
      },
      "source": [
        "def load_obj(path ):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_WpTYa0d1IC"
      },
      "source": [
        "def save_obj(obj, path ):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "        "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEtd11aqc2xT",
        "outputId": "d934a31d-d08d-4cc5-c289-7527c2be34cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sav0ZngdMUb"
      },
      "source": [
        "#load test data\n",
        "X = load_obj(path=os.path.join('drive','MyDrive', 'ROC_Derivation','X_AllData_raw.pkl'))\n",
        "y = load_obj(path=os.path.join('drive','MyDrive', 'ROC_Derivation', 'y_AllData.pkl'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brWQAlOVfEJZ"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQs3tVxtdWSt"
      },
      "source": [
        "#Control the balance of positive and negative weights, useful for unbalanced classes\n",
        "#A typical value to consider:\n",
        "# sum(negative instances) / sum(positive instances)\n",
        "\n",
        "#hard encoded from prior observatios\n",
        "scale_pos_weight = 88.83\n",
        "\n",
        "    \n",
        "#define preprocessor\n",
        "preprocessor = ColumnTransformer([('tfidfvect',\n",
        "                                   TfidfVectorizer(ngram_range=(1,3),\n",
        "                                                   max_df=0.9,\n",
        "                                                   min_df=0.1, max_features=200),\n",
        "                                   'description' #apply transformation to this column\n",
        "                                      )\n",
        "                             ],\n",
        "                             remainder=MinMaxScaler(),\n",
        "                             n_jobs=-1\n",
        "                            )\n",
        "\n",
        "#define pipeline\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                          ('clf', xgb.XGBClassifier(n_estimators=100,\n",
        "                                                    max_depth=12,\n",
        "                                                    subsample=0.9,\n",
        "                                                    scale_pos_weight = scale_pos_weight,\n",
        "                                                    eta=0.9,\n",
        "                                                    num_boost_round=15,\n",
        "                                                    tree_method='gpu_hist'\n",
        "                                                   )\n",
        "                          )\n",
        "                              ])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fb-rWm6PERK"
      },
      "source": [
        "## Bootstrap Trials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWZIVkXrfF9F",
        "outputId": "1b655c38-cf95-4b82-be3a-adba06a9bbb5"
      },
      "source": [
        "f1_arr = []\n",
        "precision_arr = []\n",
        "recall_arr = []\n",
        "\n",
        "for i in tqdm(range(867, 1001, 1)):\n",
        "    \n",
        "    #make split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                        y,\n",
        "                                                        test_size=0.05,\n",
        "                                                        stratify=y)\n",
        "    \n",
        "    #fit data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    #make a prediction from sampled data\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    \n",
        "    report_dict = classification_report(y_test,\n",
        "                                        y_pred, \n",
        "                                        output_dict=True)\n",
        "\n",
        "    save_obj(obj = report_dict, path=os.path.join('drive',\n",
        "                                             'MyDrive', \n",
        "                                             'ROC_Derivation', \n",
        "                                             'classification_dicts',\n",
        "                                             'report_dict'+ str(i)+'.pkl'))\n",
        "     \n",
        "    \n",
        "    #add the metrics to the arrays\n",
        "    # f1_arr.append(report_dict['1']['f1-score'])\n",
        "    # precision_arr.append(report_dict['1']['precision'])\n",
        "    # recall_arr.append(report_dict['1']['recall'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|‚ñç         | 432/9134 [4:18:14<86:14:33, 35.68s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyql-ch3fXG4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "remh5ttXfXCO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhN6ikfnfW4L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}