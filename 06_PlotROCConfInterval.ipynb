{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import munge_help\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,plot_roc_curve,plot_precision_recall_curve,plot_confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "X_test = utils.load_obj(path=os.path.join('data_processed', 'X_test.pkl'))\n",
    "y_test = utils.load_obj(path=os.path.join('data_processed', 'y_test.pkl'))\n",
    "\n",
    "#get path of f1 (balanced precision vs recall)\n",
    "path_f1 = os.path.join('artifacts', 'grid_search_2020-11-29_f1.pkl')\n",
    "#load the grid search objects\n",
    "grid_f1 = utils.load_obj(path_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Scale Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5395"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how many test sample we have\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get 1000 random samples from y_test\n",
    "# y_sampled = y_test.sample(n=500, replace=False)\n",
    "# #match the same indeces\n",
    "# X_sampled = X_test.loc[y_sampled.index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #instantiate pyplot objects\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "# ax = fig.gca()\n",
    "\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     #get random samples from y_test\n",
    "#     y_sampled = y_test.sample(n=100, replace=False)\n",
    "#     #match the same indeces\n",
    "#     X_sampled = X_test.loc[y_sampled.index].copy()\n",
    "    \n",
    "#     plot_precision_recall_curve(grid_f1, X_sampled, y_sampled, ax=ax, alpha=0.05)\n",
    "\n",
    "# ax.get_legend().remove()\n",
    "\n",
    "# plt.savefig(os.path.join('plots', 'confidence_prc_f1_grid.jpg'))\n",
    "\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
